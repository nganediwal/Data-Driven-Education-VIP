## 01/28/2019
This week, we were assigned to subteams and I began work on our individual project.

Having not yet been given access to actual data, I instead spent time reading the Gardner and Brooks article at the below link: https://learning-analytics.info/journals/index.php/JLA/article/view/5814 This article will form the basis of our research this semester. It details the strategies used to isolate four different data groupings/feature sets:

1. Clickstream
2. Forum
3. Assignment
4. All

And isolates five different general algorithms:

1. CART
2. Adaboost
3. Naive Bayes
4. SVM
5. L2LR

And then specifies that various hyperparameter tweaks were applied to each combination of a model and an algorithm in order to produce 46,080 models/tests.

These were then evaluated against one another with the following three techniques:

1. Naive Average
2. NHST
3. Bayesian Hierarchical Modeling

I also spent time setting up a viable build environment for models we'll construct this semester.
This build environment, run on Docker and based off an Ubuntu 18 image, is designed to provide a consistent set-up for dependencies so that everyone has all the tools they need in one place in order to run any commands needed.

It's designed to pull the docker image and launch it with a simple shell script. The docker image is listed at the following docker hub site:
https://cloud.docker.com/u/dderesearch/repository/list