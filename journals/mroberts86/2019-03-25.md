## 03/25/2019

This week, I addressed the To-Do items from last week.

The first thing I did was modify the query to run it multiple times, iterating over a pre-defined list of specified events.

The second thing was to construct a three-part structure that could theoretically produce the entire dataframe in one execution. This structure looks like this:

1. attributes.sh, which is used to run .js / sql scripts, create temporary intermediate files, calls the python script to convert these files into a .csv output dataframe, and then deletes intermediate files
2. .js scripts and sql scripts (such as attributes.js) which can read the MongoDB and PSQL databases, collect all required information, and then convert it into a temp file.
3. a python script which would take temporary files, process the data output, and construct a dataframe to output as a .csv

So far, attributes.sh, attributes.js, and attributes.py are the only scripts in this framework, and the framework is only capable of obtaining event counts, itemized by user_id, from the first week of the course. So it would, of course, be necessary to expand this to accept a range of weeks and a range of target events, and release all of that data to the temporary files, and then to the python script.

The ultimate goal, of course, is to have some kind of dataframe which might use course_id, user_id, and week as a joint primary key, and then list all attributes relevant to model training (both input attributes and output attributes such as final course grade).

As we transition into stage 2 of our overall process -- the model training section -- having a single dataframe like this will be necessary for training models.

## TODO:

1. Modify attributes.js to also collect information across a range of weeks
2. Ultimately, combine work done by other team members into the attributes.sh framework in order to collect data obtained by SQL team and Mongo team into one dataframe.