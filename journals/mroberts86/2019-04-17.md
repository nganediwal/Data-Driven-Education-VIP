## 04/17/19

I decided to extend my final week's worth of journaling to include the two days of the following week, in which I prepared code and data for our final presentation on the 17th.

In the past week and a half, here is what I have done.

1. Decided on a list of 9 event types to train on: seq_next, seq_prev, seq_goto, play_video, pause_video, edx.video.closed_captions.show, seek_video, edx.ui.lms.link_clicked
2. Attempted to select all events of each specific type from the edx.student_events_count, and then outer join each selection in order to build tuples which contain the counts of all types of event, by student, by week. This had a particular problem: I wasn't sure where to extract the student and week keys, given that any tuple might have these values missing from any one of the joined tuples. I needed to find a common place to extract student and week keys, and Shawn recommended first compiling a selection of all student/week combos present in any other selection, and then left joining it with all of the event selections.
3. Implemented this strategy that Shawn mentioned. I wrote a query which took a UNION of all these selection tables in order to extract all student/week combinations which were present, then left joined this union with all selection tables in order to obtain the final dataframe. I then created a view in the PSQL database known as events_dataframe to hold this information.
4. Joined events_dataframe and Shawn's dataframe view, which combined other assignment-related attributes and the final course success attributes. Downloaded the data from this join in order to train models.
5. Based on templates from the vip-onboarding GitHub, prepared code to read a CSV, fill in null values, separate into X and Y, and then perform tests across a wide range of hyperparameters and 2 folds. These tests use 5 types of model: Gradient Boosting, Logistic Regression, Random Forests, ADABoost, and SVMs.
6. Visualized this data as a 5 part box plot, indicating not only median and mean success but also spread of values. Visualization is available in the Final Presentation PDF.
7. Made conclusions: Gradient Boosting achieves highest maximum and median performance (based on ROC AUC), but tends to have degenerate cases which perform very poorly. ADABoost has the most consistently high performance, achieving slightly lower maximums and median but a much higher mean score.
8. Visualized one of the trees from a 100-tree random forest in order to demonstrate in the presentation how this kind of model can be used to draw conclusions about which attributes are high in possible information gain, and thus might be most useful for predicting success.
9. Prepared presentation slides.

## TODO:

Taken directly from the presentation slides, these are goals for the next semester:

* Bayesian Hierarchical Modeling
 - Implementation & Application
* Forum Data
 - This semesterâ€™s EdX forum went primarily unused
 - Worth examining Piazza in courses that use it
* Data Subsets / Feature Selection
 - Not every feature is equally useful
 - It may be easier to obtain a smaller subset of features
* Predicting Success at Checkpoints
 - Use all student data up to 1 month, or halfway point, etc.
 - See at what moment we begin to get a good prediction
* Portability to Other Classes
 - CS 1301X
 - Boilerplate Code / Models