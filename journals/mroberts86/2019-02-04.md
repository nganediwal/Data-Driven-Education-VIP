# 02/04/2019
This week, we focused in our subteam meeting on bringing all team members up to speed and getting focused on a research question. We converted our nebulous goals into a three-part process:

1. Cleaning data accessible to us from EdX / Canvas, and sorting into groupings
2. Developing a small library of models, operable on the docker image (and eventually hostable on the docker image)
3. Developing evaluation techniques for these models

Meeting with Shawn during the general meeting provided some information about the status of our data request. We learned that we would be receving access soon, but things like clickstream data might have to be limited to a single user at first, as it is hard to obtain credentials for a number of users.

We have the particular issue of extremely sensitive data in this VIP (FERPA-protected educational data). For this reason, we brainstormed methods to deal with this data. My goal is eventually to be able to perform data cleaning on the online C21U server, and then only download the cleaned data into RAM during the operation of a Docker container. Any models developed can then be run on the downloaded data, and then the results stored in permanent, host-machine storage, while the actual data is deleted entirely.

This will require an understanding of Docker secrets. Luckily, it's not yet necessary to deal with this, as we won't be needing this tool until we actually get to the stage where our data is cleaned and ready to download.

Shawn sent us access to the C21U EdX data server. It is a SQL-structured database, which we can access remotely and on which we can run various queries, create views, etc.

We were sent the following link to understand the EdX data structuring: https://edx.readthedocs.io/projects/devdata/en/latest/index.html